---
title: "Financial Analytics"
output: html_notebook
author: Tim Hulak
---

```{r}
# quantmod  used to download stock data
#install.packages("quantmod")
library(quantmod)

# highcharter used to create interactive  charts
#install.packages("highcharter")
library(highcharter)

# dygraphs used to create interactive candlestick charts
#install.packages("dygraphs")
library(dygraphs)
```


# Week 1: Introduction

#### 1.1 What Is Financial Analytics?

The art of transforming data into financial decisions using financial data analysis to answer questions like:

  + Which equity should I invest in?
  + Are banknotes genuine or forged?
  + Should we approve this client's mortgage application?
  + What is a fair selling price for a property?
  + How do you balance assets to reduce risk?
  + Should we approve this 
  + Should we approve this consumer's credit card application?

#### 1.2 Introduction to the Stock Market
```{r}

```

#### 1.3 Installing RStudio
```{r}

```

#### 1.4 Introduction to Coding with RStudio
```{r}

```

#### 1.5 More on Holding Period (Total) Return
```{r}

```


# Week 2: More on Investments
```{r}

```

#### 2.1 Wealth Index
```{r}

```

#### 2.2 Mean Periodic Return vs. Expected Return
```{r}

```

# Week 3: Market Indices, Treasury Bills

#### 3.1 What Is a Stock Market Index?
```{r}
# DJIA = SticlPrice1 + ... + StockPrice30 / Dow Divisor
dow_divisor <- 0.145

#Ex. KO, or any Blue Chip stock, increases by $1
DJIA <- round(1 / dow_divisor,2)
DJIA
```

```{r}
# Market Cap = Stock Price * # of Outstanding Shares 
# Outstanding Shares = number of ALL shares issued by a company 
# S&P is based on ADJUSTED market cap of 500 largest US companies (505 becuase some companies have 2 stocks, like BRK-A and BRK-B)
# No. of Floating SHares are shares available for PUBLIC trading

# S&P Index = Stock Price 1 * No. of Floating Shares 1 + ... + Stock Price 505 * No. of Floating Shares 505 / Index Divisor


```


#### 3.2 Stock Market Index Data with R
```{r}
# Download data for DJIA (^DJI") and S&P (^GSPC)
getSymbols(c("^DJI","^GSPC"), from = "2000-1-1", to = "2020-4-1")

# Inspect DJI
head(DJI)

```

```{r}
# Inspect GSPC
head(GSPC)
```

```{r}
# Create financial candlestick chart for DJI
chartSeries(DJI, type = "candlesticks", subset = "2020-1",theme="white")
```

```{r}
# Create financial bar chart for DJI
# Tick to <- left is open value, tick to -> right is close value
chartSeries(DJI, type = "bars", subset = "2020-1::2020-3")
```

```{r}
# Create interactive chart for DJI (open, high,low, and close)
dyRangeSelector(dyCandlestick(dygraph(DJI[ ,1:4])))
```

```{r}
# Create candlestick chart with highcharter
hchart(DJI)
```

#### 3.3 Importing Time Series Data into R
```{r}
# "/Users/timhulak/Desktop/Syracuse/FIN-654\ Financial\ Analytics/Week\ 3/va.xlsx"

va_file = "/Users/timhulak/Desktop/Syracuse/FIN-654\ Financial\ Analytics/Week\ 3/va.csv"

# Download Virgin America data from an Excel/CSV File
VA <- read.csv(file = va_file)

head(VA)
tail(VA)

# Check the type of data. It is a DataFrame, not a time series object
str(VA)
```

```{r}
# using the lookup table PDF, match the Day column with the encoding of the formatting to reformat the Day column
VA$Day <- as.Date(VA$Day, format = "%d-%b-%y")
tail(VA)
```
```{r}
# Convert VA into xts object (accessible time series) from a DataFrame
# xts( Core data (non-time columns),  ), this is from importing quantmod
Branson <- xts(VA[ ,-1], order.by = VA$Day )

str(Branson)

tail(Branson)
```

```{r}
chartSeries(Branson, type = "candlesticks", subset = "2015-8")
```


#### 3.4 Treasury Bills
```{r}
# https://www.treasury.gov/resource-center/data-chart-center/interest-rates/Pages/TextView.aspx?data=yield
face_value <-  100
discount_rate <- 2.28 / 100
discount <- face_value * discount_rate
maturity <- 52

purchase_price  <- face_value - discount

# Total Return = (Ending Value - Beginning Value) / Beginning Value
total_return <- (face_value - purchase_price) / purchase_price
round(total_return * 100,2)


```

```{r}
# Convert Annualized return to monthly return 
# 4 * 3-month return: 2.42 / 4 = 0.605%
# Ending Value = Beginning Value * (1 + Total Return)

# Approximate Solution
annualized_return <- 0.0242
months_in_a_year = 12

round(annualized_return / months_in_a_year, 6) * 100




```

```{r}
# Exact solution 
monthly_return <- 0.00605
round((1 + monthly_return) ^ (1/3) - 1,6)*100
```

```{r}
# Federal Reserve Bank of St. Louis. The symbol for FRED is DGS3MO  
# R Will download all available data (no to and from)
# This is the annualized return for 3 month treasury bills 
getSymbols("DGS3MO", src = "FRED")
head(DGS3MO)
```

```{r}
# Convert them into approximate monthly returns
# Divide them by 100 to get the proper percentage format 
risk.free <- DGS3MO / 100
risk.free <- DGS3MO / 12

# Divide by 12 to get approximate monthly return

# Or you can do (100 * 12 = 1200)
risk.free <- DGS3MO / 1200
head(risk.free)
```

# Week 4: Capital Asset Pricing Model

#### 4.1 Objective

"RISK-FREE" TREASURY BILLS WITH GUARANTEED POSITIVE RETURN 

RISKY APPLE STOCKS WITH HIGHER EXPECTED RETURN
PREDICTED ; NOT GUARANTEED !

IS APPLE STOCKS' EXPECTED RETURN HIGH ENOUGH TO JUSTIFY RISK ?

You will decide on if the expected return on Apple, Inc. stocks is high enough to justify risk.
Use Capital Asset Pricing Model and predict the “fair” return on Apple, Inc. stocks.
To do so, use the monthly return data from May 1, 2015 through April 30, 2020.

#### 4.2 Beta [β]


Use R and download the index data for S&P500 and price data for Apple, Inc. stocks.
Download the data between the first trading day of May 2015 and the last trading day of Apr 2020.

```{r}
library(quantmod)
library(PerformanceAnalytics)

# S&P 500 Index and Apple Inc. 
getSymbols(c("^GSPC","AAPL"), from = "2015-5-1", to = "2020-5-1")

head(GSPC)
head(AAPL)
```

Compute the monthly returns on AAPL and the S&P 500 Index.
```{r}
apple.monthly <- monthlyReturn(AAPL$AAPL.Adjusted)

market.monthly <- monthlyReturn(GSPC$GSPC.Adjusted)

head(apple.monthly)
head(market.monthly)
```

Download the annualized return on 3-month Treasury Bills from the Federal Reserve Bank of Saint Louis. Then convert the annualized returns into approximate monthly returns.

```{r}
getSymbols("DGS3MO", src="FRED")

head( DGS3MO )
```

To convert the annualized returns into approximate monthly returns:  First, divide them by 100. e.g. 12.17% = 0.1217 and not 12.17

Then divide them by 12 to re-scale them to approximately one month

So divide each value by 100*12 = 1200

```{r}
no.risk <- DGS3MO / 1200

head(no.risk)
```

Compute the excess returns on AAPL and the S&P 500 Index in excess of 3-month Treasury Bills.

Both apple.monthly & no.risk are xts objects in R. They are self-aware of when they exist in time.
Monthly excess return: "Reward" for taking risk

For xts objects, R computes apple.monthly − no.risk only if there is data for both objects on a given date.

EXCESS RETURN = PAST RETURN – RISK-FREE RETURN

```{r}
apple.excess.monthly <- apple.monthly - no.risk

market.excess.monthly <- market.monthly - no.risk

head(apple.excess.monthly)

head(market.excess.monthly)
```

Predicting the beta for the Risky Asset

Plot Apple's monthly excess returns versus the "U.S. market's" monthly excess returns. How volatile is Apple stocks' performance compared to the overall U.S. stock market?

Apple’s excess return -> Y (dependent variable)
“Market” excess return -> X (explanatory variable)

```{r}
chart.Regression(apple.excess.monthly, market.excess.monthly, fit = F)
```

```{r}
# Create the Linear Model
cider <- lm(apple.excess.monthly ~ market.excess.monthly)

# Plot the Linear Model
chart.Regression(apple.excess.monthly, market.excess.monthly, fit = F)
abline(cider)
```
```{r}
# View the equation

# y = Intercept + Coef * Value

# apple.excess.monthly = 0.011 + 1.165 * market.excess.monthly

# If market.excess.monthly increased by 1%, apple.excess.monthly increases by 1.165 * 1%

# 1.165 is the Predicted Beta

cider
```

This means that we predict that Apple stock is 1.165 times more volatile than the overall market 



#### 4.3 Decision and Conclusion
```{r}

```


#### 4.4 Let's Practice: JBLU
```{r}
# Get the Data
getSymbols(c("JBLU","^GSPC"), from = "2015-5-1", to = "2020-5-1" )
getSymbols("DGS3MO", src="FRED")

# Shape Data
no.risk <- DGS3MO / 1200

# Calculate Monthly Returns
mint.monthly <- monthlyReturn(JBLU[ , 6])
market.monthly <- monthlyReturn(GSPC[ , 6])

# Calculate Excess 
mint.excess.monthly <- mint.monthly - no.risk
market.excess.monthly <- market.monthly - no.risk

# Create the Linear Model
plane <- lm(mint.excess.monthly ~ market.excess.monthly)

# Plot the Linear Model
chart.Regression(mint.excess.monthly, market.excess.monthly, fit = F)
abline(plane)

plane
# y = -0.01562 + 1.36259x

```

Based on the above predicted beta of approximately 1.36, it is predicted that JBLU stock is approximately 1.36 times more volatile compared the the overall market. 

#### 4.5 Issues with CAPM
```{r}

```

# Week 5: Building Portfolios with Risky Assets
```{r}

```

#### 5.1 Introduction
```{r}

```

#### 5.2 Risk-Adjusted Performance
```{r}

```

# Week 6: Optimizing Portfolios with Risky Assets
```{r}

```

#### 6.1 Preliminary Analysis
```{r}

```

#### 6.2 Introduction to Portfolio Optimization
```{r}

```

#### 6.3 Frontier of Portfolios
```{r}

```

#### 6.4 Extra Credit
```{r}

```

# Week 7: Machine Learning: K-Nearest Neighbors Algorithm
```{r}

```


#### 7.2 Introduction
```{r}

```

#### 7.3 A Brief Review

  + Suppose you are researching the weight distribution of dogs. You predict that the mean weight of male pugs is 16 lb and the standard deviation of weight is 3 lb.
  + Consider a male pug which weighs 22 lb.
  + What is the of the weight of this pug?
  
Z = (x - mean ) / sd

Z = (22 - 16) / 3 = 2

```{r}
mean_lifespan <- 6.0
stdv <- 2.5
bluRay_Lifespan <- 3.0

Z <- (bluRay_Lifespan - mean_lifespan) / stdv


Z
```


Read in the data from the "FOOD.rdata" file 
```{r}
load("/Users/timhulak/Desktop/Syracuse/FIN-654\ Financial\ Analytics/Week\ 7/7_food.rdata")
head(FOOD)
```

# Import the package 
```{r}
library(caret)
```

#### 7.4 Introduction to KNN Algorithm

In this problem, CLASS is the dependent variable and GI and CALORIES are the independent variables 

Train the model

```{r}
FEAST <- train(CLASS ~ GI + CALORIES, data = FOOD, method = "knn")

FEAST
```

A random sample of 14 raw food items. Let's classify these raw food items: NUTS, VEGETABLES, FRUIT


Predict which class a coconut is
```{r}
COCONUT <- data.frame(GI=53, CALORIES=369)
COCONUT
```

```{r}
# predict ( model, dataframe )
predict(FEAST, COCONUT)
```

KNN is a distance-based model. All predictors should be of similar same scale to be equally influential. Therefore, we must preprocess the data (transform the data). In this case, center and scale. Center subtracts the mean of the column from each value. Scale divides the result by the standard deviation of the result. In other words, the Z score. Regardless of the range of the original data, Z Scores typically range from ≈−3 to +3. All predictors have similar scales now.

```{r}
FEAST <- train(CLASS ~ GI + CALORIES, data = FOOD, method = "knn", preProcess = c("center", "scale"))

FEAST
```

This time, the predicted class of coconut is a Fruit
```{r}
# predict ( model, dataframe )
predict(FEAST, COCONUT)
```
Predict the CLASS of jalapeno based on the KNN model FEAST.
```{r}
JALAPENO <- data.frame(GI=30, CALORIES=29)
predict(FEAST, JALAPENO)
```

Predict the CLASS of macadamia based on the KNN model FEAST.
```{r}
macadamia <- data.frame(GI=10, CALORIES=705)
predict(FEAST, macadamia)
```

Predict the CLASS of mango based on the KNN model FEAST.
```{r}
mango <- data.frame(GI=51, CALORIES=60)
predict(FEAST, mango)
```


#### 7.5 A Financial Application of the KNN Algorithm

Load the data for Euro bank notes (2 data sets)
```{r}
load("/Users/timhulak/Desktop/Syracuse/FIN-654\ Financial\ Analytics/Week\ 7/7_euro.rdata")

# Training data
head(EURO1)

# Testing Data
head(EURO2)

```


Use the data in EURO1 and train a KNN model that predicts the CLASS of a Euro banknote

Train a model (set a tune length to tell it how many K values to try. By default, the function tries odd k values starting with k=5. Even k's are not used to avoid ties.)
```{r}
FORGER <- train(CLASS ~ . , data = EURO1, method = "knn", preProcess = c("center", "scale"), tuneLength = 20)

FORGER
```

```{r}
GUESS <- predict(FORGER, EURO2)
tail(GUESS)
```

Build a confusion matrix for the results
```{r}
confusionMatrix(GUESS, EURO2$CLASS)
```

Use the model and predict the CLASS of a banknote with the following characteristics: 
  + VARIANCE=−2.97 
  + SKEWNESS=−10.33 
  + CURTOSIS=8.78 
  + ENTROPY=−2.11
  
```{r}
MONEY <- data.frame(VARIANCE = -2.97, SKEWNESS = -10.33, CURTOSIS = 8.78, ENTROPY = -2.11)

predict(FORGER, MONEY)
```

# Week 8: Machine Learning: Bayesian Binary Logistic Regression


#### 8.1 More Review

Logarithm (log): log2^8= Which power of 2 gives us 8? 3

Euler's number (e): an irrational number like pi. 2.7182818

loge^x = lnX = Natural log function of X 

The Exponential function is the inverse of natural log 


Probability Vs. Odds

Probability: 
  + P(A) = n(A) / n(S)
  + What proportion of the time an outcome is to occur
  + The probability of rolling a 2 on a 6 sided die = 1/6 (0.167)
  + Maximum value = 100%
  + Minimum value = 0%

Odds: P / (1 - P)
  + Probability it will happen divided by the probability it will not happen  
  + The odds that you will score a 2 = 0.167 / (1 - 0.167) = 0.2 [1/6 / (1 - 1/6) = 1/5]
  + Maximum value = Infinity
  + Minimum value = 0%
  

#### 8.2 Introduction
```{r}
# Load Library
library(caret)

# Load the data
load("/Users/timhulak/Desktop/Syracuse/FIN-654\ Financial\ Analytics/Week\ 8/8_titanic.rdata")

head(Titanic)
```

Task: Build Bayesian Binary Logistic Regression that predicts the probability of surviving 
```{r}
ICEBERG <- train(SURVIVED ~ ., data = Titanic, method = "bayesglm")

summary(ICEBERG)
```

Consider an 18 year old male passenger in 3rd class
```{r}
JACK <- data.frame(CLASS='third', GENDER='male', AGE=18)

predict(ICEBERG, JACK, type = "prob")

```

Consider an 18 year old female passenger in 1st class
```{r}
ROSE <- data.frame(CLASS='first', GENDER='female', AGE=18)

predict(ICEBERG, ROSE, type = "prob")
```


#### 8.3 Credit Risk Prediction

*KNN: requires 
  + Requires pre processing of predictor variables 
  + Need to set.seed() for reproducible results
  + Can apply to problems with more that two classes
* Bayesian Binary Logistic Regression
  + Do not need to preprocess predictor variables 
  + Do not need to set.seed()
  + Is not applicable to problems with more with more than two classes 

```{r}
# Load Library
library(caret)

load("/Users/timhulak/Desktop/Syracuse/FIN-654\ Financial\ Analytics/Week\ 8/8_home_loan.rdata")

head(HOME1)

head(HOME2)
```

```{r}
# Set the seed for reproducible results. This will allow the bootstrapping of the KNN algorithm to use the same random numbers each time 
set.seed(13)
HGTV <- train(DEFAULT ~ ., data = HOME1, method = "knn", preProcess = c("center", "scale"), tuneLength = 20)

HGTV
```

```{r}
# Define 
DIY <- train(DEFAULT ~.,data=HOME1,method="bayesglm")

# Define a potential customer
JOHNDOE <- data.frame(TYPE="cash", GENDER="male",CAR="yes",CHILDREN=2,RATIO=2.40)

# Will he default on his home loan?
predict(DIY,JOHNDOE, type = "prob")
# 17 0f the 33 (51.52%) nearest neighbors defaulted where as 16 (48.48%) did not
predict(HGTV,JOHNDOE, type = "prob")
```

Test the models 

```{r}
tail(HOME2)
```

```{r}
# The KNN model is 55.75% accurate
# Accuracy : 0.56
hgtv <- predict(HGTV, HOME2)
# Build confusion matrix to check
confusionMatrix(hgtv, HOME2$DEFAULT)
```


```{r}
# Logistic Regression is 60.25% accurate
# Accuracy : 0.6025 
diy <- predict(DIY, HOME2)
confusionMatrix(diy, HOME2$DEFAULT)
```

The "No Information Rate" is the most common class (in this case, 65.75% are default = yes)

Therefore, since both models did not perform better than the "No Information Rate", neither model is a good one. In order to raise the accuracy, you will need to collect more data or add more predictor variables. 

# Week 9: Machine Learning: Introduction to Artificial Neural Networks



#### 9.1 Introduction

Quantitative predictions such as "how much revenue will a movie generate" or "what would be a fair selling price for a property" 

#### 9.2 Artificial Neural Networks with Hyperbolic Tangent Activation Function

The Hyperbolic Tangent ranges from -1 to 1. 

If X >= 3, then TanH is approximately equal to 1. If X <= -3, then TanH is approximately equal to -1



```{r}
# Load the Data
load("/Users/timhulak/Desktop/Syracuse/FIN-654\ Financial\ Analytics/Week\ 9/9_ames.rdata")

tail(ames)
```
Predict the fair selling price of a property.

*The data include:
  + Price: Selling price divided by $1,000,000
  + Rooms: Number of rooms divided by 10
  + Baths: Number of bathrooms divided by 10
  + Kitchens: Number of kitchens divided by 10
  + Cars:  car capacity of garage divided by 10

When building artificial neural networks, the data should have "small" values (e.g. between -3 and 3) to satisfy the Hyperbolic Tangent. The "smaller", the better. 

```{r}
#install.packages("neuralnet")
library(neuralnet)

LOGCABIN <- neuralnet(PRICE ~ ., data = ames, hidden = 1, act.fct = "tanh")

plot(LOGCABIN)
```

Each time you build the model, you will get different weights. The algorithm starts with random coefficients and converges to a nearby local optimum solution. The local optimum solution may differ because it uses different random numbers. You can set.seed() to reproduce results (the seed number does not matter) and tell the algorithm to use the same random numbers each time it is run. 

```{r}
set.seed(1)
LOGCABIN <- neuralnet(PRICE ~ ., data = ames, hidden = 1, act.fct = "tanh")

plot(LOGCABIN)
```

Anatomy: INPUT nodes (predictors), HIDDEN note(s), OUTPUT note (predicted). There are also "BIAS" terms (the blue lines). The numbers are the "weights". 



# Step-by-step:
Use the model to predict the price of a house that has 7 rooms, 3 bathrooms, 1 kitchen, and a garage for 2 cars.

In the case of the above, the value of each predictor is multiplied by the weight. The BIAS terms are multiplied by the number in the node by it's weight (in this case, 1 * 0.04719). See Below:

  + BIAS: 1 * 0.04719
  + ROOMS: 0.7 * 0.06263
  + BATHS: 0.3 * 0.16368
  + KITCHENS: 0.1 * -0.28729
  + CARS: 0.2 * 0.24372

The sum of the above, 0.16015, is the value that flows into the HIDDEN NODE. The hidden node includes the activation function (in this case, the Hyperbolic Tangent). 

```{r}
1 * 0.04719
0.7 * 0.06263
0.3 * 0.16368
0.1 * -0.28729
0.2 * 0.24372
```

The hidden node is going to apply the Hyperbolic Tangent function to the value of 0.16015.
```{r}
FLOW <- (1 * 0.04719) + (0.7 * 0.06263) + (0.3 * 0.16368) + (0.1 * -0.28729)+ (0.2 * 0.24372)
FLOW
tanh(FLOW)
```

The outflow from the HIDDEN NODE has it's own weight, the the result of the Hyperbolic Tangent function is multiplied by the weight. Then the result is multiplied by the 2nd BIAS TERM, 1 * -0.05886. This is because both of those terms flow into the OUTPUT NODE. By default, there is no activation function in the OUTPUT NODE.
```{r}
(0.1587947 * 1.69864) + (1 * -0.05886)
```

Finally, convert the result to dollars by multiplying it by 1,000,000 (which is what we divided by in order to make the input values "small")

```{r}
OUTPUT <- (0.1587947 * 1.69864) + (1 * -0.05886)
HOME_PRICE <- OUTPUT  * 1000000
HOME_PRICE
```

Using the Algorithm

Use the model to predict the price of a house that has 7 rooms, 3 bathrooms, 1 kitchen, and a garage for 2 cars.
```{r}
NEST <- data.frame(ROOMS=7/10, BATHS=3/10, KITCHENS=1/10, CARS=2/10)

NEST
```

```{r}
predict(LOGCABIN, NEST)
```

```{r}
predict(LOGCABIN, NEST) * 1000000
```

Use the model and predict the "fair" selling price of a house in Ames, Iowa, that has nine rooms, four bathrooms, one kitchen, and a garage for two cars.

"manual"
```{r}
plot(LOGCABIN)
```

```{r}
# Calculate Values: X * weight
BIAS1 <- 1 * 0.04719
rooms <- (9 / 10) * 0.06263
baths <- (4 / 10) * 0.16368
kitchens <- (1 / 10) * -0.28729
cars <- (2 / 10) * 0.24372
BIAS2 <- 1 * -0.05886

# Calculate the flow into the hidden node
HIDDEN = BIAS1 + rooms + baths + kitchens + cars

# Calculate the output
output <- (tanh(HIDDEN) * 1.69864) + BIAS2

# multiply the output to get predicted price
output * 1000000
```

"automatic"
```{r}
NEW_HOME <- data.frame(ROOMS=9/10, BATHS=4/10, KITCHENS=1/10, CARS=3/10)

predict(LOGCABIN, NEW_HOME) * 1000000
```


#### 9.3 Artificial Neural Networks with Logistic (Sigmoid) Activation Function
```{r}
# Logistic function 
plogis(2)
```

When the logistic functions is >= 6, it is asymptotic and virtually equal to 1. When the logistic functions is <= -6, it is asymptotic and virtually equal to 0. 

```{r}
library(neuralnet)

load("/Users/timhulak/Desktop/Syracuse/FIN-654\ Financial\ Analytics/Week\ 9/9_hollywood.rdata")

tail(HOLLYWOOD)
```

Suppose you are a movie producer and you want to predict how much revenue a movie will generate.
For this purpose, you collect data from a random sample of 1,300 movies from the movie database (www.themoviedb.org). For each movie, the data set includes the following variables:

  + REVENUE : The revenue generated by the movie in $Billion
  + BUDGET : The budget required for producing the movie in $Billion.
  + RUNTIME : The runtime of the movie in hours.
  + HORROR : If the movie genre is horror or thriller, it equals 1. Otherwise, it is 0.
  + R.RATED : If the movie is R rated, it equals 1. Otherwise, it is 0.

Use R & build an artificial neural network that predicts the REVENUE generated from a movie. Include one hidden node in the artificial neural network.
Use logistic (sigmoid) as the activation function.

```{r}
# Set the seed
set.seed(1)

# Create the model with the logistic function
POPCORN <- neuralnet(REVENUE ~ ., data = HOLLYWOOD, hidden = 1, act.fct = "logistic")

# Plot the model
plot(POPCORN)
```
```{r}
tail(HOLLYWOOD)
```


```{r}
THE_GREY = data.frame(BUDGET=25000000/1000000000, RUNTIME=117/60, HORROR=0, R.RATED=1)

predict(POPCORN, THE_GREY) * 1000000000
```

```{r}
HALLOWEEN_ENDS <- data.frame(BUDGET=15000000/1000000000, RUNTIME=105/60, HORROR=1, R.RATED=1)

predict(POPCORN, HALLOWEEN_ENDS) * 1000000000
```


# 10: Machine Learning: Training and Testing Artificial Neural Networks

#### 10.1 More Review

Dependent Variable on the Y axis and independent variable on the X axis (Income depends on age)

2016 Annual income for celebrities on millions of dollars 
```{r}
library(scatterD3)

load("/Users/timhulak/Desktop/Syracuse/FIN-654\ Financial\ Analytics/Week\ 10/correlation.rdata")

head(CELEB)
```

```{r}
plot(x = CELEB$AGE, y = CELEB$USD, xlab = "Age (2016)", ylab = "Income ($Million)")
```
There is a pattern, as AGE increases INCOME tends to go down. 

```{r}
scatterD3(x = CELEB$AGE, y = CELEB$USD, xlab = "Age (2016)", ylab = "Income ($Million)", color = "green", hover_size = 4)
```

Compute the correlation coefficient 
```{r}
# Age and USD
cor(CELEB$AGE, CELEB$US)

# Age and USD
cor(CELEB$AGE, CELEB$EURO)
```

The correlation coefficient is negative, which demonstrates a negative linear relationship between AGE And INCOME.(Pearson's Correlation Coefficient -1 <= X <= 1)



#### 10.2 Training and Testing Artificial Neural Network Models


Suppose you are a real estate agent at Nashville, TN. You want to predict the "fair" selling price of a property. For this purpose, you collect data from a random sample of 1,200 properties at Nashville, TN.

For each property, the data set includes the following information:

  + PRICE : The selling price of the property divided by $1,000,000 
  + ACRES : The lot size in acres divided by 10
  + AREA : The living area in square-feet divided by 1,000
  + YEAR : The year when the property was built divided by 1,000 
  + BATHS : The number of bathrooms divided by 10
  + BRICK : If the house has brick exterior wall, it equals 1; otherwise, 0. 
  + BASEMENT : If the house has basement, it equals 1; otherwise, 0.
  
  
Use R & build an artificial neural network that predicts the PRICE of a property. Include four hidden nodes in the artificial neural network.
Use logistic (sigmoid) as the activation function.

```{r}
load("/Users/timhulak/Desktop/Syracuse/FIN-654\ Financial\ Analytics/Week\ 10/10_nashville.rdata")

head(NASH1)

head(NASH2)
```

Use R & build an artificial neural network that predicts the PRICE of a property. Include four hidden nodes in the artificial neural network.
Use logistic (sigmoid) as the activation function.

```{r}
library(neuralnet)

set.seed(99)
MANCAVE <- neuralnet(PRICE ~ ., data = NASH1, hidden = 4, act.fct = "logistic")

plot(MANCAVE)
```
Multiple linear regression model 

```{r}
SHESHED <- lm(PRICE ~ ., data = NASH1)
SHESHED
```

```{r}
tail(NASH2)
```

```{r}
mancave <- predict(MANCAVE, NASH2)
tail(mancave)
```

Test the Artificial Neural Network models performance with the correlation coefficient
```{r}
cor(mancave, NASH2$PRICE)
```

```{r}
sheshed <- predict(SHESHED, NASH2)
tail(sheshed)
```

Test the multiple linear regression models performance with the correlation coefficient
```{r}
cor(sheshed, NASH2$PRICE)
```

Since the Artificial Neural Network model performed better, lets use it to make a prediction
```{r}
# The following house sold for $165,000. Let's see how close the models get 

FORSALE <- data.frame(ACRES = 0.019, AREA = 1.566, YEAR = 1.984, BATHS = 0.3, BRICK = 1, BASEMENT = 0)

FORSALE
```

```{r}
predict(SHESHED, FORSALE) * 1000000
```

```{r}
predict(MANCAVE, FORSALE) * 1000000
```


#### 10.3 Introduction to Deep Learning

Suppose you are a movie producer and you want to predict how much revenue a movie will generate.
For this purpose, you collect data from a random sample of 1,767 movies from the movie database (www.themoviedb.org). For each movie, the data set includes the following variables:

  + REVENUE : The revenue generated by the movie in $Billion
  + BUDGET : The budget required for producing the movie in $Billion.
  + RUNTIME : The runtime of the movie in hours.
  + HORROR : If the movie genre is horror or thriller, it equals 1. Otherwise, it is 0.
  + R.RATED : If the movie is R rated, it equals 1. Otherwise, it is 0.
  

Use R & build an artificial neural network that predicts the REVENUE generated from a movie. Include three hidden nodes in the artificial neural network.
Use logistic (sigmoid) as the activation function.
```{r}
load("/Users/timhulak/Desktop/Syracuse/FIN-654\ Financial\ Analytics/Week\ 10/10_deep.rdata")

head(HOLLYWOOD)

head(WALKOFFAME)
```

Use R & build an artificial neural network that predicts the REVENUE generated from a movie. Include three hidden nodes in the artificial neural network.
Use logistic (sigmoid) as the activation function.

```{r}
library(neuralnet)

set.seed(5)
LOWBUDGET <- neuralnet(REVENUE ~ ., data = HOLLYWOOD, hidden = 3, act.fct = "logistic")

plot(LOWBUDGET)

```

Build a Deep ANN

Now build another model that has two hidden layers with three & two hidden
nodes, respectively.
Use logistic (sigmoid) as the activation function.

```{r}
set.seed(3)
BLOCKBUSTER <- neuralnet(REVENUE ~ ., data = HOLLYWOOD, hidden = c(3,2), act.fct = "logistic")

plot(BLOCKBUSTER)
```
If the neural network has multiple hidden layers, it has deep learning architecture.


Test both models using the data frame WALKOFFAME. Use each model to predict the revenue from the movies in WALKOFFAME.
 
```{r}
tail(WALKOFFAME)
```


```{r}
lowbudget <- predict(LOWBUDGET, WALKOFFAME)

tail(lowbudget)
```


```{r}
cor(lowbudget, WALKOFFAME$REVENUE)
```


```{r}
blockbuster <- predict(BLOCKBUSTER, WALKOFFAME)

tail(blockbuster)
```

```{r}
cor(blockbuster, WALKOFFAME$REVENUE)
```

The deep neural network model did not perform better than the single layer neural network (the simpler model displayed superior performance). This may be due to over-fitting the model. This means that you are going beyond the general pattern in the data and modeling the random noise in the dataset. 

```{r}
# This movie generated a revenue of $71,319,526
GRISWOLD <- data.frame(BUDGET = 0.027, RUNTIME = 1.6, HORROR = 0, R.RATED = 0)
GRISWOLD
```


```{r}
predict(LOWBUDGET,GRISWOLD) * 1000000000
```


```{r}
predict(BLOCKBUSTER,GRISWOLD) * 1000000000
```

The simpler model predicted 72,359,835 which is closer to 71,319,526

```{r}
# This movie generated a revenue of $411,556,825 million
BATMAN <- data.frame(BUDGET = 0.035, RUNTIME = 2.1, HORROR = 0, R.RATED = 0)
BATMAN
```

```{r}
predict(LOWBUDGET,BATMAN) * 1000000000
```

```{r}
predict(BLOCKBUSTER,BATMAN) * 1000000000
```

Neither model was even close. 

You can improve model performance by including more predictors, such as ACTION = 0 or 1. 


