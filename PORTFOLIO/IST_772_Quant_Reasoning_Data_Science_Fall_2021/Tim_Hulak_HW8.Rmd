---
title: "Multiple Regression/Linear Prediction Homework"
author: "Tim Hulak"
output:
  html_document:
    df_print: paged
---

```{r}
options(scipen = 999)
library(BayesFactor)
library(car)
```


I produced the material below with no assistance

# Exercises  1-8 on pages 181-182 of  *Reasoning with Data: An Introduction to Traditional and Bayesian Statistics Using R*

1. The data sets package in R contains a small data set called mtcars that contains n = 32  observations of the characteristics of different automobiles. Create a new data frame  from part of this data set using this command: myCars <- data.frame(mtcars[,1:6]).  
```{r}
data("mtcars")
head(mtcars)
dim(mtcars)
```

```{r}
myCars <- data.frame(mtcars[,1:6])
head(myCars)
dim(myCars)
```


---


2. Create and interpret a bivariate correlation matrix using cor(myCars) keeping in mind  the idea that you will be trying to predict the mpg variable. Which other variable might  be the single best predictor of mpg?  
```{r}
cor(myCars)
```

```{r}
plot(myCars$cyl, myCars$mpg, main="mpg~cyl")
abline(lm(mpg ~ cyl, data = myCars))

plot(myCars$disp, myCars$mpg, main="mpg~disp")
abline(lm(mpg ~ disp, data = myCars))

plot(myCars$hp, myCars$mpg, main="mpg~hp")
abline(lm(mpg ~ hp, data = myCars))

plot(myCars$drat, myCars$mpg, main="mpg~drat")
abline(lm(mpg ~ drat, data = myCars))

plot(myCars$wt, myCars$mpg, main="mpg~wt")
abline(lm(mpg ~ wt, data = myCars))
```


**Answer**: There appears to be a strong negative correlation between *mpg* and *disp* (**cor = -0.847**), *mpg* and *wt* (**cor = -0.867**), and *mpg* and *cyl* (**cor = -0.852**) This could be interpreted as the higher the *disp* or *wt*, the lower the *mpg*. There appears to be a strong positive correlation between *mpg* and *drat* (**cor = 0.681**). This could be interpreted as the higher the *drat*, the better the *mpg*. The strongest correlation is between *mpg* and *wt* (**cor = -0.867**) which means that *wt* might  be the single best predictor of *mpg*. 


---


3. Run a multiple regression analysis on the myCars data with lm(), using mpg as the dependent variable and wt (weight) and hp (horsepower) as the predictors. Make  sure to say whether or not the overall R-squared was significant. If it was significant,  report the value and say in your own words whether it seems like a strong result or  not. Review the significance tests on the coefficients (B-weights). For each one that  was significant, report its value and say in your own words whether it seems like a  strong result or not.  

```{r}
initial_model <- lm(mpg ~ wt + hp, myCars)
summary(initial_model)
```


```{r}
model_1 <- lm(mpg ~ cyl + disp + hp + drat + wt, myCars)
summary(model_1)
```

```{r}
model_2 <- lm(mpg ~ cyl + disp + hp  + wt, myCars)
summary(model_2)
```

```{r}
model_3 <- lm(mpg ~ cyl + hp  + wt, myCars)
summary(model_3)
```


```{r}
model_4 <- lm(mpg ~ cyl + wt, myCars)
summary(model_4)
```

**Answer**: First, a linear model using mpg as the dependent variable and wt (weight) and hp (horsepower) as the predictors was built. The p-value of *wt* was **0.00000112** and the p-value or of *hp* was **0.00145**. This is evidence that both variables are statistically significant when predicting *mpg*. The R-squared value was **0.8268** and the	Adjusted R-squared value was **0.8148**. This means that the model accounted for over 80% of the variability in the data.  

For the sake of being thorough, all of the variables were passed into a linear model. This seemed to yield an R-squared of **0.8513** and an Adjusted R-squared of **0.8227** (meaning that the model is accounting for about 83% of the variability). The highest p-value was for *drat* at **0.49964**. So, *drat* was removed and the model was run again without it. In *model 2*, the highest p-value was *disp* at **0.331386 ** (which was also the second highest p-value in the first model). Therefore, *disp* was removed and the model was run again. In *model 3*, *hp* had a p-value of **0.140015**. *hp* was removed and the model was run for a fourth time with only *cyl* and *wt*. *Model 4* maintained an R-squared of **0.8302** and an Adjusted R-squared of **0.8185** (meaning that it accounted for around 82% of the variability in the data. which was better than the initial model of *hp* and *wt* predicting *mpg*). The p-value of *cyl* was **0.001064** and the p-value of *wt* was **0.000222** (incidentally, the p-value of *cyl* was above the traditional 0.05 threshold in the other 3 models). In *model 4*, both of those variables were statistically significant and the *wt* variable might  be the single best predictor of mpg. 


---


4. Using the results of the analysis from Exercise 2, construct a prediction equation for  mpg using all three of the coefficients from the analysis (the intercept along with the  two B-weights). Pretend that an automobile designer has asked you to predict the  mpg for a car with 110 horsepower and a weight of 3 tons. Show your calculation and  the resulting value of mpg.  

```{r}
initial_model <- lm(mpg ~ wt + hp, myCars)
summary(initial_model)
```


```{r}

Intercept <- 37.22727
wt_B <- -3.87783
weight <- 3
hp_B <- -0.03177
horsepower <- 110

predicted_mpg <- Intercept + (wt_B*weight) + (hp_B*horsepower)
predicted_mpg
```



**Answer**: 22.09908 Miles Per Gallon is predicted for a car with 110 horsepower and a weight of 3 tons


---


5. Run a multiple regression analysis on the myCars data with lmBF(), using mpg as the  dependent variable and wt (weight) and hp (horsepower) as the predictors. Interpret  the resulting Bayes factor in terms of the odds in favor of the alternative hypothesis. If  you did Exercise 2, do these results strengthen or weaken your conclusions?  
```{r}
model_bf <- lmBF(mpg ~ wt + hp, data=myCars,posterior=F)
summary(model_bf)
```

**Answer**: The ratio for the relationship between the variables is **`r 1/0.0000000788`:1**. This means that there is strong evidence to reject the null hypothesis that there is no relationship between mileage and the variables. This strengthens the conclusions from Exercise 2 because we are able to reject the null hypothesis that is no relationship (meaning there *is* a relatonship)


---


6. Run lmBF() with the same model as for Exercise 4, but with the options posterior=TRUE  and iterations=10000. Interpret the resulting information about the coefficients.  
```{r}
model_bf_2 <- lmBF(mpg ~ wt + hp, data=myCars,posterior=T, iterations=10000)
summary(model_bf_2)
```

**Answer**: The HDI for *wt* had a lower bound of **-5.11112** and an upper bound of **-2.46356**. The HDI for *hp* had a lower bound of **-0.04944** and an upper bound of **-0.01246**. Neither of these straddle **0**, so we have a sense of certainty that the correlation is negative. There is strong evidence that we can reject the null hypothesis.


---


7. Run install.packages() and library() for the “car” package. The car package is “companion to applied regression” rather than more data about automobiles. Read the  help file for the vif() procedure and then look up more information online about how to  interpret the results. Then write down in your own words a “rule of thumb” for interpreting vif. 
```{r}
?vif()
```


```{r}
vif(initial_model)
```

**Answer**: According to the documentation, VIF (Variance Inflation Factors) "Calculates variance-inflation and generalized variance-inflation factors for linear, generalized linear, and other models." A “rule of thumb” for interpreting vif can be: 1 = not correlated, Between 1 and 5 = moderately correlated, and Greater than 5 = highly correlated. (Source: https://www.statisticshowto.com/variance-inflation-factor/) Since the values if the *wt* and *hp* is **1.766625**, this would be considered *moderately correlated*, if we go by that rule of thumb. 


---


8. Run vif() on the results of the model from Exercise 2. Interpret the results. Then run a  model that predicts mpg from all five of the predictors in myCars. Run vif() on those  results and interpret what you find. 
```{r}
vif(model_1)
```

**Answer**: If we go off of the rule of thumb (*1 = not correlated, Between 1 and 5 = moderately correlated, and Greater than 5 = highly correlated*), then the following can be assumed:

  - mpg & cyl (7.869010): highly correlated because it is Greater than 5
  - mpg & disp (10.463957): highly correlated because it is Greater than 5
  - mpg & hp (3.990380): moderately correlated because it is Between 1 and 5
  - mpg & drat (2.662298): moderately correlated because it is Between 1 and 5
  - mpg & wt (5.168795): highly correlated because it is Greater than 5



