---
title: "Measures of association Homework"
author: "Tim Hulak"
output:
  html_document:
    df_print: paged
---

I produced the material below with no assistance

# Exercises 3,4, 8, 9, and 10 on pages 155 and 156 of *Reasoning with Data: An Introduction to Traditional and Bayesian Statistics Using R*

3. Run cor.test() on the correlation between “area” and “perm” in the rock data set and  interpret the results. Note that you will have to use the “$” accessor to get at each of  the two variables (like this: rock$area). Make sure that you interpret both the confidence interval and the p-value that is generated by cor.test(). 
```{r}
options(scipen=999)
data("rock")
head(rock)
```

```{r}
cor.test(rock$area,rock$perm)
```

**Answer**: The output for the *Pearson's product-moment correlation* has a *lower-bound confidence interval* of **-0.6118206** and an *upper-bound confidence interval* of **-0.1267915**. Since both of these values are negative, it can be safely assumed that the correlation is skewed in a particular direction. The *p-value* is **0.005254**, which is less than the traditional alpha of **0.05**. This means that we can reject the null hypothesis that the correlation between the rock area and the rock perm is not 0. 


---


4. Create a copy of the bfCorTest() custom function presented in this chapter. Don’t forget to “source” it (meaning that you have to run the code that defines the function one  time to make R aware of it). Conduct a Bayesian analysis of the correlation between  “area” and “perm” in the rock data set. 
```{r}

#Copied from the book: 
# Reasoning with Data: An Introduction to Traditional and Bayesian Statistics Using R
# Stanton, Jeffrey M.. Reasoning with Data (p. 136). Guilford Publications. Kindle Edition. 
library("BayesFactor")  

bfCorTest <- function (x,y) #Get r from BayesFactor  
{  zx <- scale(x) #Standardize X  
  zy <- scale(y) #Standardize Y  
  zData <- data.frame(x=zx,rhoNot0=zy) #Put in a data frame  
  bfOut <- generalTestBF(x ~ rhoNot0, data=zData) #linear coefficient  
  mcmcOut <- posterior(bfOut,iterations=10000) #posterior samples  
  print(summary(mcmcOut[,"rhoNot0"])) #Show the HDI for r  
  return(bfOut) #Return Bayes factor object  
  } 

bfCorTest(rock$area,rock$perm)
```

**Answer**: The point estimate for rho is **is -0.3477**. The *95% Confidence Interval* has a lower-bound of **-0.61125** and an upper-bound of **-0.08239**. This range does not straddle zero. Finally, the Bayes Factor is approximately **8.07**. This means that there is a ratio of **`r 1/8.07`:1** odds in favor of the null  hypothesis. In other words, there is strong evidence to reject the null hypothesis in favor if the alternative hypothesis (especially when the a rule-of-thumb odds cutoff value of 3:1 is considered). 


----


8. Not unexpectedly, there is a data set in R that contains these data. The data set is  called UCBAdmissions and you can access the department mentioned above like  this: UCBAdmissions[, ,1]. Make sure you put two commas before the 1: this is a three  dimensional contingency table that we are subsetting down to two dimensions. Run  chisq.test() on this subset of the data set and make sense of the results.  
```{r}
data('UCBAdmissions')
UCBAdmissions[, ,1]
```

```{r}
chisq.test(UCBAdmissions[,,1], correct=F)
```

**Answer**: The output of the *Pearson's Chi-squared test* shows a *chi-squared* value of **17.248** with only **1** *degree of freedom*. The *p-value* is **0.0000328**, which is less than the traditional alpha of **0.05**. This means that we can reject the null hypothesis and conclude that gender and admit are not independent of each other. 


---


9. Use contingencyTableBF() to conduct a Bayes factor analysis on the UCB admissions  data. Report and interpret the Bayes factor.  
```{r}
admission_table <- contingencyTableBF(UCBAdmissions[,,1],sampleType="poisson", posterior=F)
summary(admission_table)
```

**Answer**: There is a **`r  1/1111.64`:1** ratio between the two factors. They are independent from one another (the two  factors are not associated). Because Bayes factor exceeds the rule-of-thumb ratio of **3:1**, we  can treat it as positive evidence in favor of independence.


---


10. Using the UCBA data, run contingencyTableBF() with posterior sampling. Use the  results to calculate a 95% HDI of the difference in proportions between the columns. 
```{r}
admission_table_posterior <- contingencyTableBF(UCBAdmissions[,,1], sampleType="poisson", posterior=T, iterations = 10000)
summary(admission_table_posterior)
```

```{r}
head(admission_table_posterior)
```


```{r}
male <- admission_table_posterior[,"lambda[1,1]"]/admission_table_posterior[,"lambda[2,1]"]
hist(male)
```

```{r}
female <- admission_table_posterior[,"lambda[1,2]"]/admission_table_posterior[,"lambda[2,2]"]
hist(female)
```

```{r}
difference <- male - female
head(difference)
```

```{r}
c(quantile(difference,c(0.025)),quantile(difference,c(0.975)))
```


**Answer**: The 95% HDI of the difference in proportions between the columns appears to between **-6.056048** and **-1.217753 **.
